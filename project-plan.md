# Windows realtime input assistant

We are building a Windows Command line app in C# 13 and .NET 9.  This app is basically a super powerful speech to text input assistive tool.  It uses the openai real time voice api to listen to everything the user says and then when appropriate types the transcription on the user's behalf.  The goal is to allow the user to write code, fill out forms, type documents, and anything else they might normally do on a computer keyboard with only their voice.  The goal is not to replace a mouse or touchpad, the user will still use those.  We are only replacing the keyboard.

## Special features:
 - It has two modes: Always listening mode, and hotkey mode
    - In always listening mode, it's always listening to the user's voice, wqaiting for the user to say a key command like "type text", "type code", "type", etc.  The command is used as context for the kind of text to write, for example code or text or email address or something.  Even though it's always listening, it will not type anything unless the user specifically commands it to.
    - In hotkey mode, The user holds a special key on the keyboard like f12 to activate listening.  We need to use special low level Windows keyboard hook Apis so that this doesn't interfere with the typing.  The user may start with a command for context like "type text", "type code", etc or they may simply start dictation immediately.  If the user simply pressed the key then listening should stop automatically after the user has stopped talking for a reasonable amount of time. If the user held down the keyboard key then dictation should happen as long as the user is holding down the key and then stop immediately when the key is released.
 - The user's audio is streamed to the OpenAI real time voice API, which returns the text that should be typed on the user's behalf. It uses low-level Windows keyboard apis to type on the user's behalf as if the user was typing on their own keyboard.  Typing results should be streamed back in real time from the api and typed as they are received rather than waiting for completion.
 - It never responds with audio, and does not use the audio output feature of the open ai real time voice api.  It also does not respond to commands or do anything the user says, it only types what the user says on their behalf.
 - After the user tells it to type, for additional context it will take a screenshot of the area surrounding the keyboard focus.  It will annotate this image with clear markings showing where the keyboard focus is.  It will then send this image to the openai api to help it understand context around what the user is typing, for example programming language or nonstandard words.
 - It will record nonstandard words in memory so that it can transcribe them more easily. It will include those in the context to the open ai api.  If the user corrects a spelling or word or punctuation, it will make note of that and include that in the context it sends to the open AIAPI so the problem will not happen again.
 - The user may also give a command such as "replace XYZ with ABC" or "fix XYZ" Which would generally occur after a dictation mistake. The recently dictated text and the user's command should be sent to openai to determine the correct replacements and then the recent text should be deleted and retyped according to the user's wishes. Also if the change was as a result of a dictation error then that error should be noted and included in context in the future so the error doesn't happen again.

## Implementation details:
 - This will be a simple .net command line app that runs in the background. There will be no graphical user interface.
 - Do not use any third-party libraries unless absolutely required. Interact with the opening eye api via REST and websockets directly, not with their SDK package.  Use system.text.json rather than newtonshoft json.
 - There must be an Open AI API key in the user's environment variables or specified as part of the command line arguments.  If specified as a command line argument, save it as a user preference Somewhere so it does not need to be manually specified every time in the future
 - Record any token or cost statistics returned by the openAI API and aggregate them so the user can request a report of the costs involved with using the tool

